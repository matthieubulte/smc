\section{Introduction}
\pagenumbering{arabic}
\setcounter{page}{1}
\thispagestyle{empty}

The study of complex systems is often done through mathematical modelling, allowing the simulation, analysis and prediction of their behaviour. These mathematical models require input parameters, for which only limited or no information is known. Finding these parameters from measurements of the system is called the \textit{inverse problem}. Since measurements are often noisy or sparse, and the mathematical models can be complex and expensive to evaluate, developing sound and efficient mathematical frameworks to treat the inverse problem is a complicated task.

Two prominent classes of methods for attempting to address this problem are the \textit{maximum likelihood} methods and the \textit{Bayesian} methods. In maximum likelihood methods, the solution of the inverse problem is given as the maximizer of the likelihood of the observed data. In Bayesian methods, the system is re-modeled probabilistically with random variables. This solution is given as a marginalization of the model by the observed data using Bayes' formula, as first developed by Laplace \cite{laplace1820theorie}. A theoretical and practical comparison of the two methods is given by Kaipio and Somersalo \cite{kaipio2006statistical}, including a broad introduction to solving inverse problems found in science and engineering. 

The Bayesian approach is a very general modelling and inference framework allowing to address very different kinds of statistical problems. The work by Gelman et al. \cite{gelman} gives a broad introduction to the field of \textit{Bayesian data analysis}. Based on the framework presented by Stuart \cite{stuart_2010} on Bayesian methods for inverse problems, we focus on the application of Bayesian inference to time-dependent inverse problems, called \textit{Bayesian filtering}. We will demonstrate that under weak model assumptions, the solution can be shown to be \textit{well-posed}, using a definition of well-posedness similar to Hadamard's \cite{hadamard}.

Very often, the solution of an inverse problem given in the Bayesian framework does not admit any analytical solution. Since one is interested in obtaining summarized statistics about the solution of the inverse problem, such as mean and variance, numerical approximations will involve computing integrals over the parameter space. Since volumes grow exponentially with the number of dimensions, classical methods of numerical integration cannot be used for high-dimensional problems. This phenomenon is called the \textit{curse of dimensionality}.

Fortunately, other numerical approximations were developed that do not suffer from the curse of dimensionality. Typically, such approximations work by generating pseudo-random values distributed according to the posterior distribution and use them to approximate the hard integral. Some variation of the law of large numbers will then provide dimensionality-free error bounds, making these methods suited for high-dimensional problems. A common class of algorithms falling in this category are the \textit{Markov Chain Monte Carlo} (MCMC) methods, presented by Metropolis et al. \cite{metropolis1953equation} for a specific class of problems, and later extended to the general case by Hastings \cite{hastings1970monte}. While having dimensionality-free error bounds, MCMC algorithms often need a lot of knowledge and tunning to properly operate. A simpler method to operate is \textit{importance sampling} (IS) \cite{Robert}, where the sampling is done by choosing an auxiliary distribution that is similar to the target distribution, but from which direct sampling is easier. The discrepancy between the generated samples and a sample generated from the posterior distribution is then corrected by assigning correction weights to the values of the sample. However, choosing an auxiliary distribution that is close to the target distribution is not always possible, and failling to do so results in a poor estimation of the posterior distribution.

\textit{Sequential Monte Carlo} (SMC) \cite{del_moral_2006} is a method merging ideas of MCMC and IS samplers in an attempt to solve major problems found in these other two methods. This sampler was created to approximate sequences of distributions, such as those found in data assimilation problems. However, it can also be used on an artificial sequence of distributions to interpolate between a simple initial auxiliary distribution and the true posterior. This is done by Beskos et al. \cite{beskos2015sequential} for approximating the solution of a Bayesian inverse problem associated to elliptic PDEs. By drawing parallels to particle physics, Del Moral \cite{del2013mean, del2004feynman} provides convergence results of the algorithm that will be presented in this thesis.

In their work, Allmaras et al. \cite{bayes-tutorial} give a case study-based introduction to the whole process of Bayesian techniques for solving inverse problems. This thesis will follow a similar approach, by structuring itself around a simple time-dependent Bayesian filtering problem. The system studied is the simple pendulum, an idealized model for a pendulum in which the mass of the pendulum and the air friction are ignored. It can be described by a second-order, non-linear differential equation with a parameter representing the \textit{gravitational acceleration}. We will describe the model of the pendulum, together with the inversion task of estimating the gravitational acceleration from a set of measurements taken in an experiment. 


The rest of the thesis is structured as follows. In Section 2, we describe time-dependent inverse problems and Bayesian filtering. Moreover, we show how to formulate the pendulum problem in the Bayesian framework. In Section 3, we present the construction of the SMC algorithm and show the parallels to IS and MCMC. We also present a proof of convergence of the algorithm and discuss possible extensions. We conclude the section by computing and comparing numerical solutions to the pendulum problem. Finally, Section 4 discusses other application areas and current research on SMC algorithms.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "Thesis"
%%% End:
