\section{Introduction}
\pagenumbering{arabic}
\setcounter{page}{1}
\thispagestyle{empty}

The study of complex systems is often done through mathematical modelling, allowing the simulation, analysis and prediction of their behaviour. These mathematical models require input parameters, for which only limited or no information is known. Finding these parameters from measurements of the system is called the \textit{inverse problem}. Since measurements are often noisy or sparse, and the mathematical models can be complex and expensive to evaluate, developing sound and efficient mathematical frameworks to treat the inverse problem is a complicated task.

Two prominent classes of methods for attempting to address this problem are the \textit{least squares} methods and the \textit{Bayesian} methods. While both methods rely on a \textit{likelihood function} that measures how likely it is to see some observations given a certain value of the parameter, the two methods exploit this information differently. In least squares methods, the solution of the inverse problem is given as the value of the parameter maximixing the likelihood of the observed data. In Bayesian methods, the system is re-modeled probabilistically with random variables. This solution is given as a conditionning of the model by the observed data using Bayes' rule, as first developed by Laplace \cite{laplace1820theorie}. A theoretical and practical comparison of the two methods is given by Kaipio and Somersalo \cite{kaipio2006statistical}, including a broad introduction to solving inverse problems found in science and engineering. 

The Bayesian approach is a very general modelling and inference framework allowing to address very different kinds of statistical problems. The work by Gelman et al. \cite{gelman} gives a broad introduction to the field of \textit{Bayesian data analysis}. Based on the framework presented by Stuart \cite{stuart_2010} on Bayesian methods for inverse problems, we focus on the application of Bayesian inference to time-dependent inverse problems, called \textit{Bayesian filtering}. In Bayesian filtering, we are interested in sequentially updating our knowledge about the model parameters as more observations becomes available. We will demonstrate that under weak model assumptions, the solution to the filtering problem is \textit{well-posed}, using a definition of well-posedness similar to Hadamard's \cite{hadamard}.

Very often, the solution of an inverse problem given in the Bayesian framework does not admit any analytical solution. Since one is interested in obtaining summarized statistics about the solution of the inverse problem, such as mean and variance, numerical approximations are required to compute these integrals with respect to a probability measure. We present approximations making use of weighted pseudo-random values to approximate the hard integral. A common class of algorithms falling in this category are the \textit{Markov Chain Monte Carlo} (MCMC) methods, presented by Metropolis et al. \cite{metropolis1953equation} for a specific class of problems, and later extended to the general case by Hastings \cite{hastings1970monte}. While having dimensionality-free error bounds, the numerical solution given by the MCMC algorithm cannot be extended as more data becomes available and requires to re-run the entire computation, making it unsuitable for filtering problems. A simpler method to operate is \textit{importance sampling} (IS) \cite{Robert}, where the sampling is done by choosing an auxiliary distribution that is similar to the target distribution, but from which direct sampling is easier. The discrepancy between the generated samples and a sample generated from the posterior distribution is then corrected by assigning correction weights to the values of the sample. This method can be extended to be used to approximate sequences of distributions such as those found in filtering problems, giving the \textit{Sequential Importance Sampling} (SIS) algorithm. However, choosing auxiliary distributions that are close to the target distributions is not always possible, and failling to do so results in a poor estimation of the distributions of interest.

\textit{Sequential Monte Carlo} (SMC) \cite{del_moral_2006} is a method merging ideas of MCMC and IS in an attempt to solve major problems found in these other two methods. This sampler was created to approximate sequences of distributions, such as those found in data assimilation problems. However, it can also be used on an artificial sequence of distributions to interpolate between a simple initial auxiliary distribution and the true posterior. This is done by Beskos et al. \cite{beskos2015sequential} for approximating the solution of a Bayesian inverse problem (BIP) associated to elliptic PDEs. By drawing parallels to particle physics, Del Moral \cite{del2013mean, del2004feynman} provides convergence results of the algorithm that will be presented in this thesis.

In their work, Allmaras et al. \cite{bayes-tutorial} give a case study-based introduction to the whole process of Bayesian techniques for solving inverse problems. This thesis will follow a similar approach, by structuring itself around a simple time-dependent Bayesian filtering problem (BFP). The system studied is the simple pendulum, an idealized model for a pendulum in which the mass of the pendulum and the air friction are ignored. It can be described by a second-order, non-linear ordinary differential equation with a parameter representing the \textit{gravitational acceleration}. We will describe the model of the pendulum, together with the inversion task of estimating the gravitational acceleration from a set of measurements taken in an experiment. 

The rest of the thesis is structured as follows. In Section 2, we define inverse and filtering problems, and describe the Bayesian framework as an alternative to classical minimization based solutions. We define well-posedness and prove that Bayesian inverse problems are well-posed under mild assumptions. We also describe the Pendulum problem and its Bayesian formulation and show that it is a well-posed problem. In Section 3, we show how the IS algorithm can be extended to the SIS and later SMC algorithms to efficitently approximate the solution of BFPs. We conclude with proving that these approximations provide uniform convergence bounds to the real solution of the BFPs. Section 4 then presents and analyses the numerical solution to the pendulum problem provided by the SMC algorithm and compares it to the solution given by the MCMC algorithm. Finally, Section 5 concludes the thesis with a discussion of other application areas and current research on SMC algorithms.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "Thesis"
%%% End:
